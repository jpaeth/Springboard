{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " is a demonstration of a specific challenge (benchmark) that practitioners and researchers can use together with the 3W dataset, and that is defined in the paper A Realistic and Public Dataset with Rare Undesirable Real Events in Oil Wells published in the Journal of Petroleum Science and Engineering (link here).\n",
    "Disclamer\n",
    "\n",
    "This notebook presents a demonstration. As we have not experienced all the possibilities, for example in terms of approaches, methods, parameter values, and metrics, we do not argue that the results presented here are optimal. However, these results can be used as baseline for other works.\n",
    "\n",
    "1. Choices\n",
    "The more relevant choices of the method implemented for this demonstration are:\n",
    "\n",
    "Only real instances with any type of undesirable event that have normal period are used. The types of events that do not have normal period are not appropriate for this demonstration. Only instances with enough normal period are used. An initial part of each normal period is used in the training;\n",
    "The considered metrics are calculated globally by counting the total true positives, false negatives and false positives. Samples from transient and in-regime periods are grouped as abnormal;\n",
    "The specialists consider that the normality suffers with concept drift. As we don't need to learn the concept drift itself, this method supposes that a dedicated model for each well is trained from time to time;\n",
    "Only classifiers (six in total) implemented in the scikit-learn package are used. As optimization of metrics is not a focus of this work, the parameters of the classifiers are not optimized;\n",
    "A specific sampling strategy with sliding window is used for each type of period. In normal periods, the first observatins are used for training and the last ones are used for testing. In transient periods, it is sought to use observations throughout the transient as a whole for testing (only). In in-regime periods, the first observations are privileged for testing (only);\n",
    "Before each round of training and testing:\n",
    "The used samples (not instances) are appropriately normalized with z-score;\n",
    "The variables of samples (not instances) used for training that have a number of NaNs above a threshold or that have a standard deviation below another threshold are discarded.\n",
    "For the sake of execution time, it is used a subset of the minimal set of features of the tsfresh package. Other features can improve the classifiers performances;\n",
    "All required random_state are assigned to a constant for results to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nonparametric_tests'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7b5e7c96eb65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stac'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnonparametric_tests\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstac\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mceil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nonparametric_tests'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('stac')\n",
    "import nonparametric_tests as stac\n",
    "from math import ceil\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nonparametric_tests (from versions: none)\n",
      "ERROR: No matching distribution found for nonparametric_tests\n"
     ]
    }
   ],
   "source": [
    "pip install nonparametric_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tsfresh').setLevel(logging.ERROR)\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('..', 'data')\n",
    "gamma = 'scale'\n",
    "nu = 0.5\n",
    "random_state = 1\n",
    "n_jobs = None\n",
    "clfs = {'One Class SVM - RBF':     OneClassSVM(kernel='rbf', gamma=gamma, nu=nu),\n",
    "        'One Class SVM - SIGMOID': OneClassSVM(kernel='sigmoid', gamma=gamma, nu=nu),\n",
    "        'One Class SVM - POLY':    OneClassSVM(kernel='poly', gamma=gamma, nu=nu),\n",
    "        'One Class SVM - LINEAR':  OneClassSVM(kernel='linear', gamma=gamma, nu=nu),\n",
    "        'Isolation Forest':        IsolationForest(n_jobs=n_jobs, behaviour='new',\n",
    "                                                   contamination=0, random_state=random_state),\n",
    "        'Dummy':                   DummyClassifier(strategy='constant', constant=1)\n",
    "        }\n",
    "events_names = {0: 'Normal',\n",
    "                1: 'Abrupt Increase of BSW',\n",
    "                2: 'Spurious Closure of DHSV',\n",
    "                3: 'Severe Slugging',\n",
    "                4: 'Flow Instability',\n",
    "                5: 'Rapid Productivity Loss',\n",
    "                6: 'Quick Restriction in PCK',\n",
    "                7: 'Scaling in PCK',\n",
    "                8: 'Hydrate in Production Line'\n",
    "               }\n",
    "vars = ['P-PDG',\n",
    "        'P-TPT',\n",
    "        'T-TPT',\n",
    "        'P-MON-CKP',\n",
    "        'T-JUS-CKP',\n",
    "        'P-JUS-CKGL',\n",
    "        'T-JUS-CKGL',\n",
    "        'QGL']\n",
    "columns = ['timestamp'] + vars + ['class'] \n",
    "normal_class_code = 0\n",
    "abnormal_classes_codes = [1, 2, 5, 6, 7, 8]\n",
    "sample_size = 3*60              # In observations = seconds\n",
    "min_normal_period_size = 20*60  # In observations = seconds\n",
    "split_range = 0.6               # Train size/test size\n",
    "max_samples_per_period = 15     # Limitation for safety\n",
    "df_fc_p = MinimalFCParameters() # See tsfresh's documentation\n",
    "df_fc_p.pop('sum_values')       # Excludes inappropriate feature\n",
    "df_fc_p.pop('length')           # Excludes inappropriate feature\n",
    "max_nan_percent = 0.1           # For selection of useful variables\n",
    "std_vars_min = 0.01             # For selection of useful variables\n",
    "disable_progressbar = True      # For less output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_and_file_generator(data_path, real=False, simulated=False, drawn=False):\n",
    "    for class_path in data_path.iterdir():\n",
    "        if class_path.is_dir():\n",
    "            class_code = int(class_path.stem)\n",
    "            for instance_path in class_path.iterdir():\n",
    "                if (instance_path.suffix == '.csv'):\n",
    "                    if (simulated and instance_path.stem.startswith('SIMULATED')) or \\\n",
    "                       (drawn and instance_path.stem.startswith('DRAWN')) or \\\n",
    "                       (real and (not instance_path.stem.startswith('SIMULATED')) and \\\n",
    "                       (not instance_path.stem.startswith('DRAWN'))):\n",
    "                        yield class_code, instance_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_instance(instance_path):\n",
    "    try:\n",
    "        well, instance_id = instance_path.stem.split('_')\n",
    "        df = pd.read_csv(instance_path, sep=',', header=0)\n",
    "        assert (df.columns == columns).all(), 'invalid columns in the file {}: {}'\\\n",
    "            .format(str(instance_path), str(df.columns.tolist()))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise Exception('error reading file {}: {}'.format(instance_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_samples(df, class_code):\n",
    "    # Gets the observations labels and their unequivocal set\n",
    "    ols = list(df['class'])\n",
    "    set_ols = set()\n",
    "    for ol in ols:\n",
    "        if ol in set_ols or np.isnan(ol):\n",
    "            continue\n",
    "        set_ols.add(int(ol))       \n",
    "    \n",
    "    # Discards the observations labels and replaces all nan with 0 \n",
    "    # (tsfresh's requirement)\n",
    "    df_vars = df.drop('class', axis=1).fillna(0)  \n",
    "    \n",
    "    # Initializes objects that will be return\n",
    "    df_samples_train = pd.DataFrame()\n",
    "    df_samples_test = pd.DataFrame()\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "            \n",
    "    # Find out max numbers of samples from normal, transient and in regime periods\n",
    "    #\n",
    "    # Gets indexes (first and last) without overlap with other periods\n",
    "    f_idx = ols.index(normal_class_code)\n",
    "    l_idx = len(ols)-1-ols[::-1].index(normal_class_code)\n",
    "\n",
    "    # Defines the initial numbers of samples for normal period\n",
    "    max_samples_normal = l_idx-f_idx+1-sample_size\n",
    "    if (max_samples_normal) > 0:      \n",
    "        num_normal_samples = min(max_samples_per_period, max_samples_normal)\n",
    "        num_train_samples = int(split_range*num_normal_samples)\n",
    "        num_test_samples = num_normal_samples - num_train_samples    \n",
    "    else:\n",
    "        num_train_samples = 0\n",
    "        num_test_samples = 0\n",
    "    \n",
    "    # Defines the max number of samples for transient period    \n",
    "    transient_code = class_code + 100    \n",
    "    if transient_code in set_ols:\n",
    "        # Gets indexes (first and last) with possible overlap at the beginning \n",
    "        # of this period\n",
    "        f_idx = ols.index(transient_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(transient_code)        \n",
    "        max_transient_samples = l_idx-f_idx+1-sample_size\n",
    "    else:\n",
    "        max_transient_samples = 0            \n",
    "\n",
    "    # Defines the max number of samples for in regime period\n",
    "    if class_code in set_ols:\n",
    "        # Gets indexes (first and last) with possible overlap at the beginning \n",
    "        # or end of this period\n",
    "        f_idx = ols.index(class_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(class_code)\n",
    "        if l_idx+(sample_size-1) < len(ols)-1:\n",
    "            l_idx = l_idx+(sample_size-1) \n",
    "        else:\n",
    "            l_idx = len(ols)-1\n",
    "        max_in_regime_samples = l_idx-f_idx+1-sample_size\n",
    "    else:\n",
    "        max_in_regime_samples = 0   \n",
    "        \n",
    "    # Find out proper numbers of samples from normal, transient and in regime periods\n",
    "    #\n",
    "    num_transient_samples = ceil(num_test_samples/2)\n",
    "    num_in_regime_samples = num_test_samples - num_transient_samples\n",
    "    if (max_transient_samples >= num_transient_samples) and \\\n",
    "       (max_in_regime_samples < num_in_regime_samples):\n",
    "        num_in_regime_samples = max_in_regime_samples        \n",
    "        num_transient_samples = min(num_test_samples-num_in_regime_samples, max_transient_samples)\n",
    "    elif (max_transient_samples < num_transient_samples) and \\\n",
    "         (max_in_regime_samples >= num_in_regime_samples):\n",
    "        num_transient_samples = max_transient_samples        \n",
    "        num_in_regime_samples = min(num_test_samples-num_transient_samples, max_in_regime_samples)\n",
    "    elif (max_transient_samples < num_transient_samples) and \\\n",
    "         (max_in_regime_samples < num_in_regime_samples):\n",
    "        num_transient_samples = max_transient_samples\n",
    "        num_in_regime_samples = max_in_regime_samples\n",
    "        num_test_samples = num_transient_samples+num_in_regime_samples\n",
    "    #print('num_train_samples: {}'.format(num_train_samples))\n",
    "    #print('num_test_samples: {}'.format(num_test_samples))        \n",
    "    #print('num_transient_samples: {}'.format(num_transient_samples))        \n",
    "    #print('num_in_regime_samples: {}'.format(num_in_regime_samples))\n",
    "    \n",
    "    # Extracts samples from the normal period for training and for testing\n",
    "    #\n",
    "    # Gets indexes (first and last) without overlap with other periods\n",
    "    f_idx = ols.index(normal_class_code)\n",
    "    l_idx = len(ols)-1-ols[::-1].index(normal_class_code)\n",
    "    \n",
    "    # Defines the proper step and extracts samples\n",
    "    if (num_normal_samples) > 0:  \n",
    "        if num_normal_samples == max_samples_normal:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_samples_normal-1) // (max_samples_per_period-1)\n",
    "        step_wanted = sample_size\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Extracts samples for training\n",
    "        sample_id = 0\n",
    "        for idx in range(num_train_samples):\n",
    "            f_idx_c = l_idx-sample_size+1-(num_normal_samples-1-idx)*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            #print('{}-{}-{}'.format(idx, f_idx_c, l_idx_c))\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_train = df_samples_train.append(df_sample)\n",
    "            y_train.append(normal_class_code)\n",
    "            sample_id += 1\n",
    "    \n",
    "        # Extracts samples for testing\n",
    "        sample_id = 0\n",
    "        for idx in range(num_train_samples, num_train_samples+num_test_samples):\n",
    "            f_idx_c = l_idx-sample_size+1-(num_normal_samples-1-idx)*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            #print('{}-{}-{}'.format(idx, f_idx_c, l_idx_c))\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(normal_class_code)\n",
    "            sample_id += 1\n",
    "\n",
    "    # Extracts samples from the transient period (if it exists) for testing\n",
    "    #  \n",
    "    if (num_transient_samples) > 0:    \n",
    "        # Defines the proper step and extracts samples\n",
    "        if num_transient_samples == max_transient_samples:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_transient_samples-1) // (max_samples_per_period-1)\n",
    "        step_wanted = np.inf\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Gets indexes (first and last) with possible overlap at the beginning of this period\n",
    "        f_idx = ols.index(transient_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(transient_code) \n",
    "\n",
    "        # Extracts samples\n",
    "        for idx in range(num_transient_samples):\n",
    "            f_idx_c = f_idx+idx*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            #print('{}-{}-{}'.format(idx, f_idx_c, l_idx_c))\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(transient_code)\n",
    "            sample_id += 1\n",
    "            \n",
    "    # Extracts samples from the in regime period (if it exists) for testing \n",
    "    #\n",
    "    if (num_in_regime_samples) > 0:     \n",
    "        # Defines the proper step and extracts samples\n",
    "        if num_in_regime_samples == max_in_regime_samples:\n",
    "            step_max = 1 \n",
    "        else:\n",
    "            step_max = (max_in_regime_samples-1) // (max_samples_per_period-1)\n",
    "        step_wanted = sample_size\n",
    "        step = min(step_wanted, step_max)\n",
    "        \n",
    "        # Gets indexes (first and last) with possible overlap at the beginning or end of this period\n",
    "        f_idx = ols.index(class_code)\n",
    "        if f_idx-(sample_size-1) > 0:\n",
    "            f_idx = f_idx-(sample_size-1)\n",
    "        else:\n",
    "            f_idx = 0\n",
    "        l_idx = len(ols)-1-ols[::-1].index(class_code)\n",
    "        if l_idx+(sample_size-1) < len(ols)-1:\n",
    "            l_idx = l_idx+(sample_size-1) \n",
    "        else:\n",
    "            l_idx = len(ols)-1\n",
    "\n",
    "        # Extracts samples\n",
    "        for idx in range(num_in_regime_samples):\n",
    "            f_idx_c = f_idx+idx*step\n",
    "            l_idx_c = f_idx_c+sample_size\n",
    "            #print('{}-{}-{}'.format(idx, f_idx_c, l_idx_c))\n",
    "            df_sample = df_vars.iloc[f_idx_c:l_idx_c, :]\n",
    "            df_sample.insert(loc=0, column='id', value=sample_id)\n",
    "            df_samples_test = df_samples_test.append(df_sample)\n",
    "            y_test.append(class_code)\n",
    "            sample_id += 1\n",
    "\n",
    "    return df_samples_train, y_train, df_samples_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_calc_scores(X_train, y_train, X_test, y_test, scores, clfs):\n",
    "    X_train.reset_index(inplace=True, drop=True)\n",
    "    X_test.reset_index(inplace=True, drop=True)    \n",
    "    for clf_name, clf in clfs.items():\n",
    "        try:\n",
    "            # Train\n",
    "            t0 = time()\n",
    "            if clf_name!='Dummy': \n",
    "                clf.fit(X_train)\n",
    "            else:\n",
    "                clf.fit(X_train, np.array([1]*len(y_train))) # y_train must have at least one normal sample\n",
    "            t_train = time() - t0\n",
    "                \n",
    "            # Test\n",
    "            t0 = time()\n",
    "            y_pred = clf.predict(X_test)\n",
    "            t_test = time() - t0\n",
    "            \n",
    "            # Plots actual and predicted labels\n",
    "            fig = plt.figure(figsize=(12,1))\n",
    "            ax = fig.add_subplot(111)\n",
    "            plt.plot(-(y_pred), marker=11, color='orange', linestyle='') # Inverted order (more natural)\n",
    "            plt.plot(-(y_test), marker=10, color='green', linestyle='')  # Inverted order (more natural)\n",
    "            ax.grid(False)\n",
    "            ax.set_yticks([-1, 1])\n",
    "            ax.set_yticklabels(['Normal', 'Abnormal'])\n",
    "            ax.set_title(clf_name)            \n",
    "            ax.set_xlabel('Sample')\n",
    "            ax.legend(['Predicted labels', 'Actual labels'])\n",
    "            plt.show()\n",
    "\n",
    "            # Calculates the considered scores\n",
    "            ret = precision_recall_fscore_support(y_test, y_pred, average='micro')\n",
    "            p, r, f1, _ = ret\n",
    "            scores = scores.append({'CLASSIFIER': clf_name, \n",
    "                                    'PRECISION': p,\n",
    "                                    'RECALL': r,\n",
    "                                    'F1': f1,\n",
    "                                    'TRAINING[s]': t_train, \n",
    "                                    'TESTING[s]': t_test}, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            scores = scores.append({'CLASSIFIER': clf_name, \n",
    "                                    'PRECISION': np.nan,\n",
    "                                    'RECALL': np.nan,\n",
    "                                    'F1': np.nan,\n",
    "                                    'TRAINING[s]': np.nan, \n",
    "                                    'TESTING[s]': np.nan}, ignore_index=True)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets all real instances but maintains only those with any type of undesirable event\n",
    "real_instances = pd.DataFrame(class_and_file_generator(data_path, \n",
    "                                                       real=True,\n",
    "                                                       simulated=False, \n",
    "                                                       drawn=False),\n",
    "                              columns=['class_code', 'instance_path'])\n",
    "real_instances = real_instances.loc[real_instances.iloc[:,0].isin(abnormal_classes_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each real instance with any type of undesirable event\n",
    "scores = pd.DataFrame()\n",
    "ignored_instances = 0\n",
    "used_instances = 0\n",
    "for i, row in real_instances.iterrows():\n",
    "    # Loads the current instance\n",
    "    class_code, instance_path = row\n",
    "    print('instance {}: {}'.format(i+1, instance_path))\n",
    "    df = load_instance(instance_path)\n",
    "    \n",
    "    # Ignores instances without sufficient normal periods\n",
    "    normal_period_size = (df['class']==float(normal_class_code)).sum()\n",
    "    if normal_period_size < min_normal_period_size:\n",
    "        ignored_instances += 1\n",
    "        print('\\tskipped because normal_period_size is insufficient for training ({})'\n",
    "              .format(normal_period_size))\n",
    "        continue\n",
    "    used_instances += 1\n",
    "        \n",
    "    # Extracts samples from the current real instance\n",
    "    ret = extract_samples(df, class_code)\n",
    "    df_samples_train, y_train, df_samples_test, y_test = ret\n",
    "\n",
    "    # Changes types of the labels (tsfresh's requirement)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    # We want binary classification: 1 for inliers (negative class = normal instance) and\n",
    "    # -1 for outliers (positive class = instance with anomaly) (sklearn's requirement)\n",
    "    y_test[y_test!=normal_class_code] = -1\n",
    "    y_test[y_test==normal_class_code] = 1\n",
    "    \n",
    "    # Drops the bad vars\n",
    "    good_vars = np.isnan(df_samples_train[vars]).mean(0) <= max_nan_percent\n",
    "    std_vars = np.nanstd(df_samples_train[vars], 0)\n",
    "    good_vars &= (std_vars > std_vars_min)    \n",
    "    good_vars = list(good_vars.index[good_vars])\n",
    "    bad_vars = list(set(vars)-set(good_vars))\n",
    "    df_samples_train.drop(columns=bad_vars, inplace=True, errors='ignore')\n",
    "    df_samples_test.drop(columns=bad_vars, inplace=True, errors='ignore')\n",
    "    \n",
    "    # Normalizes the samples (zero mean and unit variance)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    df_samples_train[good_vars] = scaler.fit_transform(df_samples_train[good_vars]).astype('float32')\n",
    "    df_samples_test[good_vars] = scaler.transform(df_samples_test[good_vars]).astype('float32')\n",
    "    \n",
    "    # Extracts features from samples\n",
    "    X_train = extract_features(df_samples_train, \n",
    "                               column_id='id', \n",
    "                               column_sort='timestamp', \n",
    "                               default_fc_parameters=df_fc_p,\n",
    "                               impute_function=impute,\n",
    "                               n_jobs=0,\n",
    "                               disable_progressbar=disable_progressbar)\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = extract_features(df_samples_test, \n",
    "                              column_id='id', \n",
    "                              column_sort='timestamp',\n",
    "                              default_fc_parameters=df_fc_p,\n",
    "                              impute_function=impute,\n",
    "                              n_jobs=0,\n",
    "                              disable_progressbar=disable_progressbar)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    \n",
    "    # Trains, tests and calculates the scores\n",
    "    scores = train_test_calc_scores(X_train, y_train, X_test, y_test, scores, clfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of used instances: {}'.format(used_instances))\n",
    "print('number of ignored instances: {}'.format(ignored_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('used features: {}'.format(list(df_fc_p.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores.to_csv(r'./demo_2_benchmark_anomaly_detection_scores.csv')\n",
    "#scores = pd.read_csv(r'./demo_2_benchmark_anomaly_detection_scores.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table = scores.groupby('CLASSIFIER').mean().sort_values(by=['F1'], ascending=False)\n",
    "score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.groupby('CLASSIFIER').std().sort_values(by=['F1'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs_names = list(clfs.keys())\n",
    "f1s = [scores.loc[scores['CLASSIFIER']==cn, 'F1'].values for cn in clfs_names]\n",
    "f_value_stat, p_value, ranks, pivots = stac.friedman_test(*(f1s))\n",
    "print('p_value: {}'.format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = stac.holm_test(len(pivots), pivots, clfs_names, clfs_names.index('Dummy'))\n",
    "comp, z_values_stat, p_values, adj_p_values = ret\n",
    "for i in range(len(comp)):\n",
    "    print('{}: \\n\\tp_values: {}\\n\\tadj_p_values: {}'.format(comp[i], p_values[i], adj_p_values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=0.75, style=\"whitegrid\")\n",
    "for score in scores.columns.drop(['CLASSIFIER']):\n",
    "    plt.figure(figsize=(12,1.2))\n",
    "    bplot=sns.boxplot(y='CLASSIFIER', x=score, data=scores, width=0.4, \n",
    "                      palette='colorblind', order=list(score_table.index));\n",
    "    bplot=sns.stripplot(y='CLASSIFIER', x=score, data=scores, jitter=True, marker='o', \n",
    "                        alpha=0.5, color='black', order=list(score_table.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Given the results presented above, we can state that the classifier \"IsolationForest\" presents better performance in terms of averages of the metrics F1, PRECISION and RECALL, but not in terms of the standard deviation of these metrics nor the times for training and testing.\n",
    "\n",
    "After a non-parametric multiple comparison analysis, we verified that the classifier \"IsolationForest\" produces statistically different F1 mean value compared to the dummy classifier.\n",
    "\n",
    "Therefore, it is proved that machine learning algorithm can be used to detect anomalies in oil wells."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
